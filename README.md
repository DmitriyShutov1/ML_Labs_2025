
**Выполнил:** Шутов Дмитрий Олегович, группа М8О-407Б-22

## Датасеты

1. **Bank Marketing**  
   [Ссылка на датасет](https://www.kaggle.com/datasets/henriqueyamahata/bank-marketing)  
   Задача: прогнозирование ответа клиента на предложение банка. Датасет содержит информацию о клиентах банка и их откликах на маркетинговую кампанию.

2. **Car Prices**  
   [Ссылка на датасет](https://www.kaggle.com/datasets/CooperUnion/cardataset)  
   Задача: прогнозирование рыночной стоимости автомобиля. Датасет включает характеристики автомобилей и их рыночные цены.

---

## Содержание лабораторных работ

### Лабораторная работа №1-5
1. Выбор начальных условий:
   - Подбор наборов данных для классификации и регрессии с обоснованием.
   - Выбор метрик качества.
2. Создание бейзлайна и оценка качества моделей.
3. Улучшение бейзлайна:
   - Предобработка данных, визуализация, новые признаки, подбор гиперпараметров.
   - Проверка гипотез, формирование улучшенного бейзлайна, обучение и оценка моделей.
4. Имплементация алгоритма вручную:
   - Реализация моделей для классификации и регрессии.
   - Обучение, оценка, сравнение с бейзлайном.
   - Добавление техник улучшенного бейзлайна и повторная оценка.

Дополнительно: подведение итогов, сравнение результатов всех алгоритмов из лабораторных 1–5. 
Итоговое сравнение всех алгоритмов и моделей и заключение содержится в отдельном ноутбуке в папке labs в данном репозитории.

### Итоговый ноутбук
Содержит сводное сравнение всех алгоритмов по классификации и регрессии, включая таблицы с метриками и выводы.

---

## СРАВНИТЕЛЬНЫЙ АНАЛИЗ АЛГОРИТМОВ

##КЛАССИФИКАЦИЯ (BANK MARKETING DATASET)
В задаче классификации наилучшие результаты продемонстрировал алгоритм градиентного бустинга. Улучшенная версия Gradient Boosting показала F1-score 0.536 и ROC-AUC 0.816, что является максимальным значением среди всех исследованных алгоритмов. Это объясняется природой алгоритма, который последовательно исправляет ошибки предыдущих базовых моделей, что особенно эффективно на сложных, нелинейно разделимых данных.

Второе место занял Random Forest с F1-score 0.529 и ROC-AUC 0.802. Ансамблевый подход, основанный на бэггинге, обеспечил хорошую стабильность и устойчивость к переобучению. Decision Tree после улучшений показал значительный прогресс: F1-score вырос с 0.326 до 0.517, а ROC-AUC увеличился с 0.626 до 0.784. Этот результат наглядно демонстрирует важность регуляризации для деревьев решений.

Logistic Regression и KNN показали умеренные результаты с F1-score 0.510 и 0.503 соответственно. Линейная модель достигла своего "потолка" качества быстрее других алгоритмов, в то время как KNN, несмотря на улучшения, не смог превзойти более сложные ансамблевые методы.

##РЕГРЕССИЯ (CARS DATASET)
В задаче регрессии результаты оказались более сбалансированными между разными алгоритмами. Лучший результат по RMSE показал KNN (4797), что можно объяснить природой данных: автомобили с похожими характеристиками имеют схожие цены, и локальные методы хорошо работают в таких условиях.

Random Forest и Linear Regression показали близкие результаты с RMSE 4953 и 4792 соответственно. Random Forest обеспечил лучшее объяснение дисперсии (R²=0.965), в то время как Linear Regression, несмотря на свою простоту, показала стабильно хорошее качество, что свидетельствует о наличии линейных зависимостей в данных.

Gradient Boosting для регрессии показал значительный прогресс после улучшений: RMSE снизился с 6941 до 5118, а R² увеличился с 0.931 до 0.963. Этот результат демонстрирует, насколько критически важна правильная настройка гиперпараметров для градиентного бустинга.

##ЭФФЕКТИВНОСТЬ УЛУЧШЕНИЙ МОДЕЛЕЙ
Анализ разницы между базовыми и улучшенными версиями моделей выявил несколько важных закономерностей. Наибольший абсолютный прирост качества наблюдался у Gradient Boosting в задаче классификации: F1-score увеличился на 0.186 пункта. Это объясняется высокой чувствительностью алгоритма к гиперпараметрам, таким как learning rate, n_estimators и глубина деревьев.

Decision Tree показал максимальный относительный рост: F1-score улучшился на 58%, а ROC-AUC увеличился на 25%. Этот результат наглядно демонстрирует проблему переобучения деревьев решений и эффективность методов регуляризации (ограничение глубины, минимальное количество образцов в листе).

Наименьший прогресс от улучшений показали Linear Regression и KNN. Линейная модель в регрессии практически не изменила качество (R² уменьшился на 0.001), что объясняется простотой модели и ограниченными возможностями для улучшения через гиперпараметры. KNN показал умеренное улучшение, но изначально уже находился на высоком уровне качества.

##СРАВНЕНИЕ SKLEARN И САМОСТОЯТЕЛЬНЫХ РЕАЛИЗАЦИЙ
Сравнение результатов библиотечных реализаций из scikit-learn и самостоятельно написанных алгоритмов показало конкурентоспособность наших имплементаций. В задаче классификации sklearn Gradient Boosting превзошел нашу реализацию на 1.5% по F1-score, что можно считать статистически незначимым отличием.

В задаче регрессии наши реализации в некоторых случаях превзошли библиотечные: Random Forest manual показал RMSE 4544 против 4953 у sklearn (улучшение на 8.3%), а KNN manual также показал немного лучший результат. Это свидетельствует о корректной реализации алгоритмов и понимании их внутренней механики.

Наиболее заметное преимущество sklearn реализаций проявилось в скорости работы и стабильности, что ожидаемо для промышленных библиотек. Однако качественные показатели наших реализаций подтверждают глубокое понимание алгоритмов и способность их практической реализации.

##ВЫЯВЛЕННЫЕ ЗАКОНОМЕРНОСТИ И ПРАКТИЧЕСКИЕ ВЫВОДЫ
Анализ результатов позволил выявить несколько ключевых закономерностей. Сложные ансамблевые алгоритмы (Gradient Boosting, Random Forest) показали наилучшее конечное качество, но требуют тщательной настройки гиперпараметров. Простые модели (Linear Regression, KNN) быстрее достигают своего "потолка" качества, но могут быть предпочтительны для быстрого прототипирования.

Влияние улучшений существенно различается в зависимости от алгоритма. Gradient Boosting и Decision Tree получили максимальную выгоду от оптимизации гиперпараметров и препроцессинга данных, в то время как Linear Regression практически не изменила своих показателей.

Для задачи классификации на данных Bank Marketing наиболее эффективными оказались техники работы с несбалансированными классами (взвешивание, подбор порога), в то время как для регрессии на данных Cars ключевым улучшением стало логарифмическое преобразование целевой переменной.

##ЗАКЛЮЧЕНИЕ
Проведенная серия лабораторных работ позволила не только освоить технические аспекты реализации и настройки алгоритмов машинного обучения, но и развить аналитические навыки оценки и сравнения моделей. Полученные результаты демонстрируют понимание как теоретических основ алгоритмов, так и практических аспектов их применения.

Самостоятельные реализации алгоритмов показали свою конкурентоспособность с промышленными библиотеками, что подтверждает глубокое усвоение материала. Разработанная методология исследований, включающая создание бейзлайнов, их последовательное улучшение и сравнительный анализ, может быть успешно применена для решения реальных задач машинного обучения.

---
## Инструкция по запуску

1. Скачайте все ноутбуки из папки labs.
2. Откройте Google Colab.
3. Запустите все ячейки ноутбука последовательно.
5. Для просмотра итогового сравнения всех алгоритмов запустите:
'Итоговое сравнение и вывод.ipynb`

